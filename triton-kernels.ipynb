{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae37cd5-1bd9-4d8a-9db6-fe6c500ecccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a sparse attention using triton using the following methods\n",
    "# the Q and K are divided into equal sized chunks\n",
    "# assume  QxK^T to be [Q0,Q1,....Qn-1]*[K0,K1,....Kn-1] where each of them are equal sized chunks from the initial embeddings.\n",
    "# in the full product if Q0*K0 then you do the regular multiplication, but if Q0*K1 or whenever the indices are not same, do avg(Q0)*avg(K1) and then broadcast this value in the shape of that grid.\n",
    "# create a triton kernel which implements the above operation if i==j then intra-index, if i!=j then inter-index\n",
    "# generate code and test case for the kernels first before proceeding to the full implementation\n",
    "# the argument and the return signature should exactly match that of the torch.nn.functional.scaled_dot_product_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b084ed-7c5f-4205-950b-251e05d70131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scaled_dot_product_attention(query, key, value, attn_mask=None, dropout_p=0.0,\n",
    "#         is_causal=False, scale=None, enable_gqa=False) -> torch.Tensor:\n",
    "#     L, S = query.size(-2), key.size(-2)\n",
    "#     scale_factor = 1 / math.sqrt(query.size(-1)) if scale is None else scale\n",
    "#     attn_bias = torch.zeros(L, S, dtype=query.dtype)\n",
    "#     if is_causal:\n",
    "#         assert attn_mask is None\n",
    "#         temp_mask = torch.ones(L, S, dtype=torch.bool).tril(diagonal=0)\n",
    "#         attn_bias.masked_fill_(temp_mask.logical_not(), float(\"-inf\"))\n",
    "#         attn_bias.to(query.dtype)\n",
    "\n",
    "#     if attn_mask is not None:\n",
    "#         if attn_mask.dtype == torch.bool:\n",
    "#             attn_bias.masked_fill_(attn_mask.logical_not(), float(\"-inf\"))\n",
    "#         else:\n",
    "#             attn_bias += attn_mask\n",
    "\n",
    "#     if enable_gqa:\n",
    "#         key = key.repeat_interleave(query.size(-3)//key.size(-3), -3)\n",
    "#         value = value.repeat_interleave(query.size(-3)//value.size(-3), -3)\n",
    "\n",
    "#     attn_weight = query @ key.transpose(-2, -1) * scale_factor\n",
    "#     attn_weight += attn_bias\n",
    "#     attn_weight = torch.softmax(attn_weight, dim=-1)\n",
    "#     attn_weight = torch.dropout(attn_weight, dropout_p, train=True)\n",
    "#     return attn_weight @ value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b760d4ef-2248-4fcb-8a5e-2fc3cb992f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "@triton.jit\n",
    "def chunked_attention_kernel(\n",
    "    Q_ptr,                   # ptr to Q,  shape=[M, D]\n",
    "    K_ptr,                   # ptr to K,  shape=[D, N]\n",
    "    Out_ptr,                 # ptr to Out,shape=[M, N]\n",
    "    # offsets for sub-chunk (i, j):\n",
    "    q_row_offset,            # integer\n",
    "    k_col_offset,            # integer\n",
    "    out_row_offset,          # integer\n",
    "    out_col_offset,          # integer\n",
    "    \n",
    "    # strides in memory for Q, K, Out:\n",
    "    q_stride_m,              # typically D\n",
    "    q_stride_d,              # typically 1\n",
    "    k_stride_d,              # typically N\n",
    "    k_stride_n,              # typically 1\n",
    "    out_stride_m,            # typically N\n",
    "    out_stride_n,            # typically 1\n",
    "\n",
    "    M, N, D,                 # full matrix sizes\n",
    "    chunk_size_m,            # sub-chunk M size\n",
    "    chunk_size_n,            # sub-chunk N size\n",
    "    \n",
    "    avg_q_val,               # precomputed scalar avg(Q_i)\n",
    "    avg_k_val,               # precomputed scalar avg(K_j)\n",
    "    is_same_chunk,           # 1 => i == j (intra-chunk), 0 => i != j (inter-chunk)\n",
    "\n",
    "    BLOCK_M: tl.constexpr,   # block size along M\n",
    "    BLOCK_N: tl.constexpr,   # block size along N\n",
    "    BLOCK_K: tl.constexpr    # block size along K (reduction dimension)\n",
    "):\n",
    "    \"\"\"\n",
    "    Single-block kernel for chunked attention sub-block:\n",
    "      - If is_same_chunk == 1 (i == j): do a block-tiled matmul of shape [chunk_size_m, chunk_size_n].\n",
    "      - If is_same_chunk == 0 (i != j): broadcast the product of avg_q_val * avg_k_val.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Compute row/col indices within this sub-chunk\n",
    "    row_id = tl.arange(0, BLOCK_M)  # [0..BLOCK_M-1]\n",
    "    col_id = tl.arange(0, BLOCK_N)  # [0..BLOCK_N-1]\n",
    "\n",
    "    # 2) Mask to ensure we do not go out of the sub-chunk\n",
    "    #    (for small or partial blocks)\n",
    "    row_mask = row_id < chunk_size_m\n",
    "    col_mask = col_id < chunk_size_n\n",
    "\n",
    "    # Base pointers in Q, K, Out for this sub-chunk\n",
    "    # Q base is Q_ptr + q_row_offset*D\n",
    "    # K base is K_ptr + k_col_offset\n",
    "    # Out base is Out_ptr + out_row_offset*N + out_col_offset\n",
    "    # We apply them after we add the row/col offset inside the load/store macros.\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # CASE 1: Intra-chunk => matmul with blocking along D\n",
    "    # ------------------------------------------------------------------\n",
    "    if is_same_chunk == 1:\n",
    "        # Initialize accumulator\n",
    "        acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)\n",
    "\n",
    "        # We do a loop over K dimension in BLOCK_K chunks\n",
    "        # Typical approach: each iteration loads sub-block from Q and K\n",
    "        # Then does a blockwise matmul-accumulate.\n",
    "        for kk in range(0, D, BLOCK_K):\n",
    "            # Current chunk size for this iteration\n",
    "            kk_size = tl.minimum(BLOCK_K, D - kk)\n",
    "\n",
    "            # -----------------\n",
    "            # LOAD A SUB-BLOCK FROM Q => shape [BLOCK_M, BLOCK_K]\n",
    "            # Q rows: (q_row_offset + row_id)\n",
    "            # Q cols: (kk + [0..BLOCK_K-1])\n",
    "            q_row_ptr = Q_ptr + (q_row_offset + row_id) * q_stride_m\n",
    "            q_col_ptr = q_row_ptr + (kk) * q_stride_d  # offset in the D dimension\n",
    "            # gather from Q\n",
    "            # shape = [BLOCK_M, kk_size]\n",
    "            # We'll do an outer loop over row_id + an inner loop over the partial K\n",
    "            q_vals = tl.zeros((BLOCK_M, BLOCK_K), dtype=tl.float32)\n",
    "            # load only the needed columns\n",
    "            load_k_idx = tl.arange(0, BLOCK_K)\n",
    "            col_mask_k = load_k_idx < kk_size  # valid columns\n",
    "            # for each row in [BLOCK_M]:\n",
    "            for r in range(BLOCK_M):\n",
    "                if row_mask[r]:\n",
    "                    # pointer for row r\n",
    "                    row_ptr = q_col_ptr[r]\n",
    "                    # load the columns\n",
    "                    q_vals[r, :] = tl.load(\n",
    "                        row_ptr + load_k_idx * q_stride_d,\n",
    "                        mask=col_mask_k, \n",
    "                        other=0.0\n",
    "                    )\n",
    "\n",
    "            # -----------------\n",
    "            # LOAD A SUB-BLOCK FROM K => shape [BLOCK_K, BLOCK_N]\n",
    "            # K rows: (kk + [0..BLOCK_K-1])\n",
    "            # K cols: (k_col_offset + col_id)\n",
    "            k_col_ptr = K_ptr + (k_col_offset + col_id) * k_stride_n\n",
    "            k_row_ptr = k_col_ptr + (kk) * k_stride_d\n",
    "            k_vals = tl.zeros((BLOCK_K, BLOCK_N), dtype=tl.float32)\n",
    "            row_mask_k = load_k_idx < kk_size\n",
    "            for c in range(BLOCK_N):\n",
    "                if col_mask[c]:\n",
    "                    # pointer for col c\n",
    "                    col_ptr = k_row_ptr + c * k_stride_n\n",
    "                    k_vals[:, c] = tl.load(\n",
    "                        col_ptr + load_k_idx * k_stride_d,\n",
    "                        mask=row_mask_k,\n",
    "                        other=0.0\n",
    "                    )\n",
    "\n",
    "            # -----------------\n",
    "            # ACCUMULATE: (BLOCK_M x BLOCK_K) @ (BLOCK_K x BLOCK_N)\n",
    "            # We do a naive triple nested loop in Triton to keep it simple.\n",
    "            for red_i in range(BLOCK_K):\n",
    "                # if red_i < kk_size\n",
    "                red_mask = red_i < kk_size\n",
    "                if red_mask:\n",
    "                    q_slice = q_vals[:, red_i]  # shape [BLOCK_M]\n",
    "                    k_slice = k_vals[red_i, :]  # shape [BLOCK_N]\n",
    "                    acc += q_slice[:, None] * k_slice[None, :]\n",
    "\n",
    "        # Write the result to Out\n",
    "        # address for (row_id, col_id):\n",
    "        out_ptr = Out_ptr + (out_row_offset + row_id) * out_stride_m + (out_col_offset) * out_stride_n\n",
    "        for r in range(BLOCK_M):\n",
    "            if row_mask[r]:\n",
    "                row_out_ptr = out_ptr[r]\n",
    "                for c in range(BLOCK_N):\n",
    "                    if col_mask[c]:\n",
    "                        tl.store(\n",
    "                            row_out_ptr + (col_id[c] * out_stride_n),\n",
    "                            acc[r, c]\n",
    "                        )\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # CASE 2: Inter-chunk => broadcast avg_q_val * avg_k_val\n",
    "    # ------------------------------------------------------------------\n",
    "    else:\n",
    "        # Single scalar\n",
    "        prod_scalar = avg_q_val * avg_k_val\n",
    "\n",
    "        # Write to entire sub-block\n",
    "        out_ptr = Out_ptr + (out_row_offset + row_id) * out_stride_m + (out_col_offset) * out_stride_n\n",
    "        for r in range(BLOCK_M):\n",
    "            if row_mask[r]:\n",
    "                row_out_ptr = out_ptr[r]\n",
    "                for c in range(BLOCK_N):\n",
    "                    if col_mask[c]:\n",
    "                        tl.store(\n",
    "                            row_out_ptr + col_id[c] * out_stride_n,\n",
    "                            prod_scalar\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375a4f24-84bc-4f98-b4aa-ed157102d88e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
